{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8198ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "from IPython.display import Image\n",
    "#from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f971dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d048d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_model = load_model('../models/age_model_pretrained.h5')\n",
    "gender_model = load_model('../models/gender_model_pretrained.h5')\n",
    "emotion_model = load_model('../models/emotion_model_pretrained.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac7c57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels\n",
    "\n",
    "age_labels = ['1-2', '3-9', '10-20', '21-27', '28-45', '46-65', '66-116']\n",
    "gender_labels = ['male', 'female']\n",
    "emotion_labels = ['Happy', 'Angry/Sad', 'Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cb4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test images\n",
    "\n",
    "man_test_1 = '../tests/test_images/man-lowres.png'\n",
    "man_test_2 = '../tests/test_images/man-background.png'\n",
    "man_test_3 = '../tests/test_images/man-kn95.jpg'\n",
    "man_test_4 = '../tests/test_images/man.jpg'\n",
    "man_test_5 = '../tests/test_images/kartik_aryan.jpg'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "woman_test_1 = '../tests/test_images/woman-hijab.jpg'\n",
    "\n",
    "\n",
    "group_test_1 = '../tests/test_images/group-angle.jpg'\n",
    "group_test_2 = '../tests/test_images/group-big.jpg'\n",
    "group_test_3 = '../tests/test_images/family.jpg'\n",
    "group_test_4 = '../tests/test_images/group-lowres.jpg'\n",
    "\n",
    "group_test_5 = '../tests/test_images/group-child.jpg'\n",
    "\n",
    "\n",
    "\n",
    "img_path = '../tests/test_images/priyanka_chopra.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494a023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pil_image = Image(filename=woman_test_1)\n",
    "# display(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8794dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imread(img_path).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a95b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(img):\n",
    "    test_image = cv2.imread(img)\n",
    "    gray = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier('../models/cv2_cascade_classifier/haarcascade_frontalface_default.xml')\n",
    "    #glass_cascade\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if len(faces)==0:\n",
    "        return 'Face Not Detected'\n",
    "    else:\n",
    "        i = 0\n",
    "        subjects = []\n",
    "        for (x,y,w,h) in faces:\n",
    "            i = i+1\n",
    "            cv2.rectangle(test_image,(x,y),(x+w,y+h),(203,12,255),2)\n",
    "\n",
    "            img_gray= gray[y:y+h,x:x+w]\n",
    "\n",
    "            #emotion prediction\n",
    "            emotion_img = cv2.resize(img_gray, (48, 48), interpolation = cv2.INTER_AREA)\n",
    "            emotion_img_array = np.array(emotion_img)\n",
    "            emotion_input = np.expand_dims(emotion_img_array, axis=0)\n",
    "            output_emotion = emotion_labels[np.argmax(emotion_model.predict(emotion_input, verbose=0))]\n",
    "\n",
    "            #gender prediction\n",
    "            gender_img= cv2.resize(img_gray, (100,100), interpolation = cv2.INTER_AREA)\n",
    "            gender_img_array = np.array(gender_img)\n",
    "            gender_input = np.expand_dims(gender_img_array, axis=0)\n",
    "            output_gender = gender_labels[np.argmax(gender_model.predict(gender_input, verbose=0))]\n",
    "\n",
    "            #age prediction\n",
    "            age_img = cv2.resize(img_gray, (200,200), interpolation = cv2.INTER_AREA)\n",
    "            age_input = age_img.reshape(-1, 200, 200, 1)\n",
    "            output_age = age_labels[np.argmax(age_model.predict(age_input, verbose=0))]\n",
    "\n",
    "            output_str = f'\\nSubject: {str(i)} \\nGender: {output_gender} \\nAge range: {output_age} \\nEmotion: {output_emotion}\\n'\n",
    "            #print(output_str)\n",
    "\n",
    "            info= {'Subject': i, 'Gender': output_gender, 'Age': output_age, 'Emotion': output_emotion}\n",
    "            subjects.append(info)\n",
    "            col = (0,255,0)\n",
    "            cv2.putText(test_image, str(i), (x,y), cv2.FONT_HERSHEY_SIMPLEX, 1, col, 2)\n",
    "        \n",
    "   \n",
    "    return subjects,  plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59599ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = prediction(group_test_3)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9b0f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in result:\n",
    "    \n",
    "#     for k,v in i.items():\n",
    "#         print(f'{k}: {v}')\n",
    "#     print('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd8ec87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
